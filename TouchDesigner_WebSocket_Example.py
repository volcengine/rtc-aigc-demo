"""
TouchDesigner WebSocket æ¥æ”¶ç«¯ç¤ºä¾‹
åœ¨ TouchDesigner ä¸­åˆ›å»ºä¸€ä¸ª Web Server DATï¼Œå¹¶å°†æ­¤è„šæœ¬è®¾ç½®ä¸ºå…¶å›è°ƒå¤„ç†è„šæœ¬

é…ç½® Web Server DAT:
- Protocol: WebSocket
- Local Port: 8080
- Enable WebSocket: On
- Callbacks: è®¾ç½®ä¸ºæ­¤è„šæœ¬æ‰€åœ¨çš„ DAT

æ­¤è„šæœ¬å°†æ¥æ”¶æ¥è‡ª Web ç«¯çš„è¯­éŸ³å¯¹è¯æ¶ˆæ¯å’ŒçŠ¶æ€æ›´æ–°ï¼Œ
å¹¶å¯ä»¥é©±åŠ¨ç›¸åº”çš„å¯è§†åŒ–æ•ˆæœã€‚
"""

import json

# å…¨å±€å˜é‡æ¥å­˜å‚¨å½“å‰çŠ¶æ€
current_status = 'idle'
last_message = ''
last_user = ''
current_volume = 0
current_spectrum = []

def onWebSocketReceiveText(dat, data, peer):
    """
    æ¥æ”¶ WebSocket æ–‡æœ¬æ¶ˆæ¯çš„å›è°ƒå‡½æ•°
    
    Args:
        dat: Web Server DAT å¯¹è±¡
        data: æ¥æ”¶åˆ°çš„æ–‡æœ¬æ•°æ®
        peer: å®¢æˆ·ç«¯ä¿¡æ¯
    """
    global current_status, last_message, last_user, current_volume, current_spectrum
    
    try:
        # è§£æ JSON æ¶ˆæ¯
        message = json.loads(data)
        message_type = message.get('type', '')
        
        print(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯ç±»å‹: {message_type}")
        
        if message_type == 'user_message':
            # ç”¨æˆ·æ¶ˆæ¯
            handle_user_message(message)
            
        elif message_type == 'ai_message':
            # AI æ¶ˆæ¯
            handle_ai_message(message)
            
        elif message_type == 'status_update':
            # çŠ¶æ€æ›´æ–°
            handle_status_update(message)
            
        elif message_type == 'audio_data':
            # éŸ³é¢‘æ•°æ®
            handle_audio_data(message)
            
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
    except Exception as e:
        print(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")

def handle_user_message(message):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    global last_message, last_user
    
    text = message.get('text', '')
    user = message.get('user', '')
    definite = message.get('definite', False)
    paragraph = message.get('paragraph', False)
    
    last_message = text
    last_user = user
    
    print(f"ğŸ‘¤ ç”¨æˆ·æ¶ˆæ¯: {text}")
    
    # æ›´æ–° TouchDesigner ä¸­çš„æ–‡æœ¬æ˜¾ç¤º
    update_text_display(text, 'user')
    
    # è§¦å‘ç”¨æˆ·æ¶ˆæ¯å¯è§†åŒ–æ•ˆæœ
    trigger_user_visual_effect(text, definite, paragraph)

def handle_ai_message(message):
    """å¤„ç† AI æ¶ˆæ¯"""
    global last_message, last_user
    
    text = message.get('text', '')
    user = message.get('user', '')
    definite = message.get('definite', False)
    paragraph = message.get('paragraph', False)
    is_interrupted = message.get('isInterrupted', False)
    
    last_message = text
    last_user = user
    
    print(f"ğŸ¤– AI æ¶ˆæ¯: {text}")
    
    # æ›´æ–° TouchDesigner ä¸­çš„æ–‡æœ¬æ˜¾ç¤º
    update_text_display(text, 'ai')
    
    # è§¦å‘ AI æ¶ˆæ¯å¯è§†åŒ–æ•ˆæœ
    trigger_ai_visual_effect(text, definite, paragraph, is_interrupted)

def handle_status_update(message):
    """å¤„ç†çŠ¶æ€æ›´æ–°"""
    global current_status
    
    status = message.get('status', 'idle')
    current_status = status
    
    print(f"ğŸ”„ çŠ¶æ€æ›´æ–°: {status}")
    
    # æ ¹æ®çŠ¶æ€æ›´æ–°å¯è§†åŒ–æ•ˆæœ
    if status == 'speaking':
        trigger_ai_speaking_effect()
    elif status == 'listening':
        trigger_listening_effect()
    elif status == 'thinking':
        trigger_thinking_effect()
    elif status == 'idle':
        trigger_idle_effect()

def handle_audio_data(message):
    """å¤„ç†éŸ³é¢‘æ•°æ®"""
    global current_volume, current_spectrum
    
    volume = message.get('volume', 0)
    spectrum = message.get('spectrum', [])
    
    current_volume = volume
    current_spectrum = spectrum
    
    # æ›´æ–°éŸ³é¢‘å¯è§†åŒ–
    update_audio_visualization(volume, spectrum)

def update_text_display(text, speaker_type):
    """æ›´æ–°æ–‡æœ¬æ˜¾ç¤º"""
    try:
        # å‡è®¾æœ‰ä¸€ä¸ª Text TOP ç”¨äºæ˜¾ç¤ºæ¶ˆæ¯
        text_top = op('message_display')
        if text_top:
            # æ ¹æ®è¯´è¯è€…ç±»å‹è®¾ç½®ä¸åŒçš„é¢œè‰²
            if speaker_type == 'user':
                text_top.par.text = f"User: {text}"
                # è®¾ç½®ç”¨æˆ·æ¶ˆæ¯é¢œè‰²ï¼ˆè“è‰²ï¼‰
                text_top.par.fontcolorr = 0.2
                text_top.par.fontcolorg = 0.6
                text_top.par.fontcolorb = 1.0
            else:
                text_top.par.text = f"AI: {text}"
                # è®¾ç½® AI æ¶ˆæ¯é¢œè‰²ï¼ˆç»¿è‰²ï¼‰
                text_top.par.fontcolorr = 0.2
                text_top.par.fontcolorg = 1.0
                text_top.par.fontcolorb = 0.3
    except:
        print("âš ï¸ æ›´æ–°æ–‡æœ¬æ˜¾ç¤ºå¤±è´¥")

def trigger_user_visual_effect(text, definite, paragraph):
    """è§¦å‘ç”¨æˆ·æ¶ˆæ¯çš„å¯è§†åŒ–æ•ˆæœ"""
    try:
        # ç¤ºä¾‹ï¼šè§¦å‘ç”¨æˆ·è¾“å…¥çš„ç²’å­æ•ˆæœ
        particle_comp = op('user_particles')
        if particle_comp:
            # æ ¹æ®æ¶ˆæ¯é•¿åº¦è°ƒæ•´ç²’å­æ•°é‡
            particle_count = min(len(text) * 2, 1000)
            particle_comp.par.count = particle_count
            
            # å¦‚æœæ˜¯å®Œæ•´å¥å­ï¼Œè§¦å‘çˆ†å‘æ•ˆæœ
            if definite or paragraph:
                particle_comp.par.birthrate = 100
                # 1ç§’åæ¢å¤æ­£å¸¸
                run("op('user_particles').par.birthrate = 10", delayFrames=30)
    except:
        print("âš ï¸ è§¦å‘ç”¨æˆ·å¯è§†åŒ–æ•ˆæœå¤±è´¥")

def trigger_ai_visual_effect(text, definite, paragraph, is_interrupted):
    """è§¦å‘ AI æ¶ˆæ¯çš„å¯è§†åŒ–æ•ˆæœ"""
    try:
        # ç¤ºä¾‹ï¼šAI å“åº”çš„å…‰ç¯æ•ˆæœ
        ai_visual = op('ai_visual')
        if ai_visual:
            # æ ¹æ®æ¶ˆæ¯é•¿åº¦è°ƒæ•´æ•ˆæœå¼ºåº¦
            intensity = min(len(text) / 50.0, 1.0)
            ai_visual.par.intensity = intensity
            
            # å¦‚æœè¢«æ‰“æ–­ï¼Œæ˜¾ç¤ºç‰¹æ®Šæ•ˆæœ
            if is_interrupted:
                ai_visual.par.colorr = 1.0  # çº¢è‰²è¡¨ç¤ºè¢«æ‰“æ–­
                ai_visual.par.colorg = 0.3
                ai_visual.par.colorb = 0.3
            else:
                ai_visual.par.colorr = 0.3  # æ­£å¸¸ç»¿è‰²
                ai_visual.par.colorg = 1.0
                ai_visual.par.colorb = 0.3
    except:
        print("âš ï¸ è§¦å‘ AI å¯è§†åŒ–æ•ˆæœå¤±è´¥")

def trigger_ai_speaking_effect():
    """AI è¯´è¯çŠ¶æ€çš„è§†è§‰æ•ˆæœ"""
    try:
        # å¯åŠ¨è¯´è¯çŠ¶æ€çš„åŠ¨ç”»
        speaking_anim = op('speaking_animation')
        if speaking_anim:
            speaking_anim.par.play = True
            
        # è°ƒæ•´æ•´ä½“åœºæ™¯äº®åº¦
        scene_light = op('main_light')
        if scene_light:
            scene_light.par.dimmer = 0.8
    except:
        print("âš ï¸ è§¦å‘ AI è¯´è¯æ•ˆæœå¤±è´¥")

def trigger_listening_effect():
    """ç›‘å¬çŠ¶æ€çš„è§†è§‰æ•ˆæœ"""
    try:
        # å¯åŠ¨ç›‘å¬çŠ¶æ€çš„è„‰å†²æ•ˆæœ
        listening_pulse = op('listening_pulse')
        if listening_pulse:
            listening_pulse.par.amplitude = 0.5
            
        # è°ƒæ•´æ•´ä½“åœºæ™¯ä¸ºè“è‰²è°ƒ
        scene_light = op('main_light')
        if scene_light:
            scene_light.par.colorr = 0.3
            scene_light.par.colorg = 0.6
            scene_light.par.colorb = 1.0
    except:
        print("âš ï¸ è§¦å‘ç›‘å¬æ•ˆæœå¤±è´¥")

def trigger_thinking_effect():
    """æ€è€ƒçŠ¶æ€çš„è§†è§‰æ•ˆæœ"""
    try:
        # å¯åŠ¨æ€è€ƒçŠ¶æ€çš„æ—‹è½¬æ•ˆæœ
        thinking_rotation = op('thinking_rotation')
        if thinking_rotation:
            thinking_rotation.par.speed = 2.0
            
        # è°ƒæ•´æ•´ä½“åœºæ™¯ä¸ºæ©™è‰²è°ƒ
        scene_light = op('main_light')
        if scene_light:
            scene_light.par.colorr = 1.0
            scene_light.par.colorg = 0.7
            scene_light.par.colorb = 0.2
    except:
        print("âš ï¸ è§¦å‘æ€è€ƒæ•ˆæœå¤±è´¥")

def trigger_idle_effect():
    """ç©ºé—²çŠ¶æ€çš„è§†è§‰æ•ˆæœ"""
    try:
        # æ¢å¤é»˜è®¤çŠ¶æ€
        default_anim = op('default_animation')
        if default_anim:
            default_anim.par.play = True
            
        # æ¢å¤é»˜è®¤å…‰ç…§
        scene_light = op('main_light')
        if scene_light:
            scene_light.par.colorr = 1.0
            scene_light.par.colorg = 1.0
            scene_light.par.colorb = 1.0
            scene_light.par.dimmer = 0.6
    except:
        print("âš ï¸ è§¦å‘ç©ºé—²æ•ˆæœå¤±è´¥")

def update_audio_visualization(volume, spectrum):
    """æ›´æ–°éŸ³é¢‘å¯è§†åŒ–"""
    try:
        # æ›´æ–°éŸ³é‡è¡¨
        volume_meter = op('volume_meter')
        if volume_meter:
            volume_meter.par.value0 = volume / 255.0  # å½’ä¸€åŒ–åˆ° 0-1
            
        # æ›´æ–°é¢‘è°±æ˜¾ç¤º
        if spectrum and len(spectrum) > 0:
            spectrum_viz = op('spectrum_viz')
            if spectrum_viz:
                # å°†é¢‘è°±æ•°æ®å†™å…¥ CHOP æˆ– DAT
                for i, freq_value in enumerate(spectrum):
                    if i < 32:  # é™åˆ¶ä¸ºå‰32ä¸ªé¢‘æ®µ
                        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„ TouchDesigner ç½‘ç»œç»“æ„è°ƒæ•´
                        channel_name = f'freq_{i:02d}'
                        # spectrum_viz.chan(channel_name).val = freq_value / 255.0
    except:
        print("âš ï¸ æ›´æ–°éŸ³é¢‘å¯è§†åŒ–å¤±è´¥")

def onWebSocketReceiveBytes(dat, data, peer):
    """
    æ¥æ”¶ WebSocket äºŒè¿›åˆ¶æ¶ˆæ¯çš„å›è°ƒå‡½æ•°
    ï¼ˆå¦‚æœéœ€è¦ä¼ è¾“éŸ³é¢‘æ•°æ®ç­‰äºŒè¿›åˆ¶å†…å®¹æ—¶ä½¿ç”¨ï¼‰
    """
    print(f"ğŸ“¦ æ”¶åˆ°äºŒè¿›åˆ¶æ•°æ®ï¼Œå¤§å°: {len(data)} å­—èŠ‚")

def onWebSocketOpen(dat, peer):
    """WebSocket è¿æ¥å»ºç«‹æ—¶çš„å›è°ƒ"""
    print(f"ğŸ”— WebSocket è¿æ¥å·²å»ºç«‹: {peer}")

def onWebSocketClose(dat, peer):
    """WebSocket è¿æ¥å…³é—­æ—¶çš„å›è°ƒ"""
    print(f"âŒ WebSocket è¿æ¥å·²å…³é—­: {peer}")

# è¾…åŠ©å‡½æ•°ï¼šè·å–å½“å‰çŠ¶æ€ä¿¡æ¯ï¼ˆå¯åœ¨å…¶ä»–åœ°æ–¹è°ƒç”¨ï¼‰
def get_current_status():
    """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
    return {
        'status': current_status,
        'last_message': last_message,
        'last_user': last_user,
        'volume': current_volume,
        'spectrum_length': len(current_spectrum)
    }

# ä½¿ç”¨ç¤ºä¾‹ï¼š
# åœ¨ TouchDesigner ä¸­ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–çŠ¶æ€ï¼š
# status_info = op('websocket_handler').get_current_status()
# print(status_info)
